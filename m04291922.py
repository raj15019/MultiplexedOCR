# -*- coding: utf-8 -*-
"""M04291922.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CgA6GWsXDXQDR220EgWzF4AFHBUVSLdj

# Connect to Google Drive
"""

# !rm -rf /content/drive
from google.colab import drive
# drive.mount('/content/drive', force_remount=True)
drive.mount('/content/drive')

"""# Environment Setup"""

import torch
TORCH_VERSION = ".".join(torch.__version__.split(".")[:2])
CUDA_VERSION = torch.__version__.split("+")[-1]
print("torch: ", TORCH_VERSION, "; cuda: ", CUDA_VERSION)

!python --version

!gcc --version

import torchvision
print(".".join(torchvision.__version__.split(".")))
import torchaudio
print(".".join(torchaudio.__version__.split(".")))

!pip install yacs

!pip install pyclipper

!pip install ftfy

!pip install submitit

!pip install black

!pip install flask

!pip install click==8.0.0

!pip install isort

!pip install flake8

# !pip install -U google-cloud-aiplatform "shapely<2"
!pip install shapely==1.8.5

import shapely
print(shapely.__version__)

"""# Import Code from github"""

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content"
!pwd

# Commented out IPython magic to ensure Python compatibility.
!rm -rf MultiplexedOCR
!git clone https://github.com/raj15019/MultiplexedOCR.git
# %cd MultiplexedOCR

!git pull

!pwd

"""# Install and Develop"""

!python setup.py build_ext install

!python setup.py build develop

"""# Demo Code (From Notebook) 
[Demo Notebook](https://github.com/facebookresearch/MultiplexedOCR/blob/main/notebook/inference/demo.ipynb)
"""

import argparse
import torch
import time
from PIL import Image
import getpass
from multiplexer.config import cfg
from multiplexer.config.parser import override_cfg_from_arg_opts
from multiplexer.checkpoint import DetectionCheckpointer
from multiplexer.data import make_data_loader
from multiplexer.data.transforms import build_transforms
from multiplexer.engine.text_inference import compute_result_logs, load_image, render_box_multi_text
from multiplexer.modeling import build_model
from multiplexer.structures.image_list import to_image_list

user = getpass.getuser()
config_file = f"/content/drive/MyDrive/OCR/config.yaml"
model_weight = f"/content/drive/MyDrive/OCR/PMLX1G.pth"
img_dir = f"/content/drive/MyDrive/OCR/imgs/"

cfg.merge_from_file(config_file)

opts = ["MODEL.WEIGHT", model_weight]
cfg.merge_from_list(opts)

model = build_model(cfg)

model = model.to(cfg.MODEL.DEVICE)

checkpointer = DetectionCheckpointer(cfg, model)
_ = checkpointer.load(cfg.MODEL.WEIGHT)

model.eval()

transforms = build_transforms(cfg, False)

def predict_on_image(image_path):
    image = load_image(image_path)
    img, _ = transforms(image, None)
    images = to_image_list(img, cfg.DATALOADER.SIZE_DIVISIBILITY)
    images = images.to(cfg.MODEL.DEVICE)

    with torch.no_grad():
        prediction_dict = model(images)
        
    global_prediction = prediction_dict["global_prediction"][0]
    test_image_width, test_image_height = global_prediction.size

    img = load_image(image_path)
    width, height = img.size
    resize_ratio = float(height) / test_image_height
    global_prediction = global_prediction.resize((width, height))
    prediction_dict["rotated_boxes_5d"] = None
    prediction_dict["boxes"] = global_prediction.bbox.tolist()
    use_seg_poly = cfg.MODEL.SEG.USE_SEG_POLY
    if cfg.MODEL.TRAIN_DETECTION_ONLY:
        prediction_dict["scores"] = [1.0 for _ in range(len(global_prediction))]  # dummy
        use_seg_poly = True
        prediction_dict["masks"] = global_prediction.get_field("masks").get_polygons()
    else:
        if cfg.MODEL.ROI_BOX_HEAD.INFERENCE_USE_BOX:
            prediction_dict["scores"] = global_prediction.get_field("scores").tolist()
        if not use_seg_poly:
            prediction_dict["masks"] = global_prediction.get_field("mask").cpu().numpy()
        else:
            prediction_dict["masks"] = global_prediction.get_field("masks").get_polygons()

    polygon_format = "polygon"
    result_logs_dict = compute_result_logs(
        prediction_dict=prediction_dict,
        cfg=cfg,
        img=img,
        polygon_format=polygon_format,
        use_seg_poly=use_seg_poly,
    )
    result_logs = result_logs_dict["result_logs"]
    
    img_vis = img.copy()
    render_box_multi_text(
        cfg=cfg,
        image=img_vis,
        result_logs_dict=result_logs_dict,
        resize_ratio=resize_ratio,
    )
    
    return img_vis

print(img_dir)

predict_on_image(img_dir + "menu01.jpg")

predict_on_image(img_dir + "menu02.jpg")

predict_on_image(img_dir + "menu03.jpg")

predict_on_image(img_dir + "menu04.jpg")

predict_on_image(img_dir + "menu05.jpg")

predict_on_image(img_dir + "menu06.jpg")

predict_on_image(img_dir + "living+room_60_4.jpg")

img_dir = f"/content/drive/MyDrive/OCR/datasets/MLT19/train/imgs/"
predict_on_image(img_dir + "tr_img_01245.jpg")

predict_on_image(img_dir + "tr_img_02470.jpg")

predict_on_image(img_dir + "tr_img_02715.jpg")

predict_on_image(img_dir + "tr_img_03205.jpg")

predict_on_image(img_dir + "tr_img_05655.jpg")

predict_on_image(img_dir + "tr_img_06390.jpg")

predict_on_image(img_dir + "tr_img_07125.jpg")

predict_on_image(img_dir + "tr_img_07860.jpg")

predict_on_image(img_dir + "tr_img_08105.jpg")

predict_on_image(img_dir + "tr_img_08350.jpg")

predict_on_image(img_dir + "tr_img_08595.jpg")

predict_on_image(img_dir + "tr_img_08840.jpg")

predict_on_image(img_dir + "tr_img_09085.jpg")

predict_on_image(img_dir + "tr_img_09330.jpg")

predict_on_image(img_dir + "tr_img_09575.jpg")

predict_on_image(img_dir + "tr_img_09820.jpg")

!pwd

"""# Training"""

# Commented out IPython magic to ensure Python compatibility.
!pwd
# %cd ..
# %cd ..
# %cd ..
# %cd ..
!pip uninstall apex
!pip uninstall pyramid
!pip uninstall zope.interface

!pip install zope.interface
!pip install pyramid

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/NVIDIA/apex
# %cd apex
!python3 setup.py install

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/MultiplexedOCR
# %cd content
# %cd MultiplexedOCR
!pwd

!git pull

!python3 tools/train_net.py --config-file config.yaml

"""# Evaluation on **MLT19**"""



"""## Step 1: generate intermediate results

"""

train_flow="PMLX1G_public"
yaml_dir="/content/drive/MyDrive/OCR"
model_name="PMLX1G"
min_size_test=2000
max_size_test=2560

!python3 tools/launch_test.py \
--dataset mlt19 \
--name pmlx_test_$train_flow \
--yaml_dir $yaml_dir \
--yaml config.yaml \
INPUT.MIN_SIZE_TEST $min_size_test \
INPUT.MAX_SIZE_TEST $max_size_test \
MODEL.WEIGHT ${yaml_dir}/${model_name}.pth \
TEST.VIS False \
OUTPUT_DIR /content/drive/MyDrive/OCR/multiplexer/test/$train_flow \
OUTPUT.MLT19.TASK1 False \
OUTPUT.MLT19.TASK3 False \
OUTPUT.MLT19.TASK4 False \
OUTPUT.MLT19.VALIDATION_EVAL False \
OUTPUT.MLT19.INTERMEDIATE True \
OUTPUT.MLT19.INTERMEDIATE_WITH_PKL False \
OUTPUT.ZIP_PER_GPU True

"""## Step 2: generate files for submission"""

train_flow="PMLX1G_public"
model_name="PMLX1G"
min_size_test=2000
max_size_test=2560
confidence_type="det"
char_map_version="none"
lexicon="none"
score_det=0.2
score_rec_seq=0.8

!python3 tools/launch_eval.py \
--name multiplexer_mlt19_test_${task}_${train_flow} \
--run_type local \
==cache_dir "/tmp/$USER/mlt19_test/${train_flow}/cache_files/" \
==char_map_version $char_map_version \
==confidence_type $confidence_type \
==intermediate_results /content/drive/MyDrive/OCR/mlt19_test/${model_name}_mlt19_intermediate.zip \
==protocol intermediate \
==lexicon $lexicon \
==score_det $score_det \
==score_rec_seq $score_rec_seq \
==seq on \
==split test \
==task task4 \
==zip_per_gpu